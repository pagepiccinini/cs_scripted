ls()
## SET WORKING DIRECTORY#
setwd("~/Desktop/Experiments/CS E-S Scripted/Results/data")#
## LOAD LIBRARIES#
library(dplyr)#
library(tidyr)#
#
## READ IN DATA#
word_info = read.table("word_information.txt", header=T, sep="\t", stringsAsFactors=F)#
sub_20_sent = read.table("raw_data/sub_20_sentences_INITIAL.txt", header=T, sep="\t", stringsAsFactors=F)#
## ORGANIZE DATA#
# Add comments for sentences#
sub_20_sent_comments = sub_20_sent %>%#
	separate(sentence, into=c("prefix", "number", "sent_comment"), sep="_") %>%#
	mutate(sentence=paste(prefix, number, sep="_")) %>%#
	select(-prefix, -number)#
#
# Combine sentence and word files and remove 'copa' tokens#
sub_20 = inner_join(sub_20_sent_comments, word_info)#
sub_20 = filter(sub_20, word!="copa")#
## CHECK IF SHOULD BE EXCLUDED#
sub_20_sub = sub_20 %>%#
	filter(is.na(sent_comment))#
xtabs(~language+context+phoneme, sub_20_sub)
quit()
